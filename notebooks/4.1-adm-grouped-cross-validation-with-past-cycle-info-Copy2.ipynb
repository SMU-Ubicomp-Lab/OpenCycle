{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab --no-import-all inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most general form of cross-validation, with history\n",
    "---\n",
    "\n",
    "This provides little personalization, and still avoids the issue of using a subject's future data for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "\n",
    "# add the 'src' directory as one where we can import modules\n",
    "src_dir = path.join(\"..\", 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# import my method from the source code\n",
    "%aimport features.build_features\n",
    "%aimport models.fit_predict\n",
    "%aimport visualization.visualize\n",
    "from features.build_features import previous_value\n",
    "from models.fit_predict import cv_predict\n",
    "from visualization.visualize import modified_bland_altman_plot, residual_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.4\n"
     ]
    }
   ],
   "source": [
    "import keras; print(keras.__version__)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPool1D\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = path.join(\"..\", \"data\", \"interim\", \"df.csv\")\n",
    "df = pd.read_csv(file, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $n$ days of temperature measurements.\n",
    "\n",
    "The use case requires deleting those whose ovulation occurs before these $n$ days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_DAYS = 10\n",
    "df = df[df.L_PREOVULATION > NUMBER_OF_DAYS]  # No use predicting backward in time.\n",
    "temp_measurements = [\"TEMP\" + str(i + 1) for i in range(NUMBER_OF_DAYS)]\n",
    "features += temp_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TEMP1',\n",
       " 'TEMP2',\n",
       " 'TEMP3',\n",
       " 'TEMP4',\n",
       " 'TEMP5',\n",
       " 'TEMP6',\n",
       " 'TEMP7',\n",
       " 'TEMP8',\n",
       " 'TEMP9',\n",
       " 'TEMP10']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df.L_PREOVULATION\n",
    "grouping = df.ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=10, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "22687/22687 [==============================] - 21s - loss: 39.9168    \n",
      "Epoch 2/20\n",
      "22687/22687 [==============================] - 21s - loss: 40.8522    \n",
      "  180/22687 [..............................] - ETA: 20s - loss: 24.1370Epoch 2/20\n",
      "22687/22687 [==============================] - 21s - loss: 40.2394    \n",
      "  375/22687 [..............................] - ETA: 18s - loss: 18.5779\n",
      "  225/22687 [..............................] - ETA: 16s - loss: 14.7950Epoch 2/20\n",
      "Epoch 2/20\n",
      "22687/22687 [==============================] - 21s - loss: 15.4703    \n",
      "Epoch 3/20\n",
      "22687/22687 [==============================] - 21s - loss: 15.5538    \n",
      "22687/22687 [==============================] - 22s - loss: 15.4012    \n",
      "22495/22687 [============================>.] - ETA: 0s - loss: 15.6845Epoch 3/20\n",
      "    5/22687 [..............................] - ETA: 68s - loss: 5.2955Epoch 3/20\n",
      "  170/22687 [..............................] - ETA: 26s - loss: 15.2456\n",
      "  245/22687 [..............................] - ETA: 21s - loss: 15.2518Epoch 3/20\n",
      "18580/22687 [=======================>......] - ETA: 4s - loss: 15.6402Epoch 1/20\n",
      "22687/22687 [==============================] - 26s - loss: 15.4894    \n",
      "22460/22687 [============================>.] - ETA: 0s - loss: 15.4402Epoch 4/20\n",
      " 2595/22688 [==>...........................] - ETA: 44s - loss: 182.6668\n",
      "Epoch 4/20\n",
      "22687/22687 [==============================] - 27s - loss: 15.3790    \n",
      "  140/22687 [..............................] - ETA: 17s - loss: 19.2032Epoch 4/20\n",
      "19910/22687 [=========================>....] - ETA: 3s - loss: 15.2629\n",
      "Epoch 2/20\n",
      "22687/22687 [==============================] - 26s - loss: 15.3829    \n",
      "Epoch 5/20\n",
      "22687/22687 [==============================] - 26s - loss: 15.3232    \n",
      "  195/22687 [..............................] - ETA: 19s - loss: 18.8929\n",
      "Epoch 5/20\n",
      "Epoch 5/20\n",
      "22688/22688 [==============================] - 21s - loss: 15.0301    \n",
      "Epoch 3/20\n",
      " 3030/22688 [===>..........................] - ETA: 17s - loss: 13.5393\n",
      "Epoch 6/20\n",
      " 3110/22688 [===>..........................] - ETA: 16s - loss: 13.8562\n",
      "Epoch 6/20\n",
      "22687/22687 [==============================] - 21s - loss: 15.4467    \n",
      "Epoch 6/20\n",
      "22688/22688 [==============================] - 23s - loss: 14.9645    \n",
      "19405/22687 [========================>.....] - ETA: 3s - loss: 15.1451Epoch 4/20\n",
      "22687/22687 [==============================] - 23s - loss: 15.4485    \n",
      "Epoch 7/20\n",
      " 2900/22688 [==>...........................] - ETA: 22s - loss: 15.8008\n",
      "Epoch 7/20\n",
      "  185/22687 [..............................] - ETA: 27s - loss: 12.0556\n",
      "Epoch 7/20\n",
      "19370/22687 [========================>.....] - ETA: 3s - loss: 15.2948\n",
      "19250/22687 [========================>.....] - ETA: 3s - loss: 15.2324Epoch 5/20\n",
      " 2975/22688 [==>...........................] - ETA: 21s - loss: 14.6843\n",
      "22380/22687 [============================>.] - ETA: 0s - loss: 15.3186Epoch 8/20\n",
      "22687/22687 [==============================] - 21s - loss: 15.3252    \n",
      "22435/22687 [============================>.] - ETA: 0s - loss: 15.3305Epoch 8/20\n",
      "  615/22687 [..............................] - ETA: 27s - loss: 13.6480\n",
      "Epoch 8/20\n",
      "22688/22688 [==============================] - 23s - loss: 14.9320    \n",
      "Epoch 6/20\n",
      "22687/22687 [==============================] - 22s - loss: 15.3046    \n",
      "Epoch 9/20\n",
      "  205/22687 [..............................] - ETA: 23s - loss: 15.7769\n",
      "Epoch 9/20\n",
      "22687/22687 [==============================] - 22s - loss: 15.3115    \n",
      "Epoch 9/20\n",
      "22688/22688 [==============================] - 21s - loss: 14.8895    \n",
      "19380/22687 [========================>.....] - ETA: 3s - loss: 15.1327Epoch 7/20\n",
      "22687/22687 [==============================] - 21s - loss: 15.3121    \n",
      " 3215/22688 [===>..........................] - ETA: 18s - loss: 14.7456Epoch 10/20\n",
      "22687/22687 [==============================] - 21s - loss: 15.3215    \n",
      "Epoch 10/20\n",
      "22687/22687 [==============================] - 22s - loss: 15.3961    \n",
      "Epoch 10/20\n",
      "17925/22687 [======================>.......] - ETA: 4s - loss: 15.4642\n",
      "Epoch 8/20\n",
      "22687/22687 [==============================] - 21s - loss: 15.2963    \n",
      "Epoch 11/20\n",
      "22687/22687 [==============================] - 22s - loss: 15.3087    \n",
      "Epoch 11/20\n",
      "22687/22687 [==============================] - 21s - loss: 15.3982    \n",
      "Epoch 11/20\n",
      "19160/22687 [========================>.....] - ETA: 3s - loss: 15.1682\n",
      "Epoch 9/20\n",
      "22687/22687 [==============================] - 24s - loss: 15.2883    \n",
      "Epoch 12/20\n",
      "22687/22687 [==============================] - 24s - loss: 15.2850    \n",
      " 4065/22688 [====>.........................] - ETA: 17s - loss: 13.6996Epoch 12/20\n",
      "  975/22687 [>.............................] - ETA: 20s - loss: 13.0629\n",
      "Epoch 12/20\n",
      "22688/22688 [==============================] - 20s - loss: 14.8872    \n",
      "18885/22687 [=======================>......] - ETA: 3s - loss: 15.2744Epoch 10/20\n",
      "21465/22687 [===========================>..] - ETA: 1s - loss: 15.4094\n",
      "Epoch 13/20\n",
      "22687/22687 [==============================] - 20s - loss: 15.2894    \n",
      "  375/22687 [..............................] - ETA: 15s - loss: 10.0244Epoch 13/20\n",
      " 5075/22688 [=====>........................] - ETA: 15s - loss: 16.8638\n",
      "  895/22687 [>.............................] - ETA: 18s - loss: 13.9904Epoch 13/20\n",
      "17525/22687 [======================>.......] - ETA: 5s - loss: 15.3567\n",
      "Epoch 11/20\n",
      "21285/22687 [===========================>..] - ETA: 1s - loss: 15.2616\n",
      "22530/22687 [============================>.] - ETA: 0s - loss: 15.2580Epoch 14/20\n",
      "  205/22687 [..............................] - ETA: 26s - loss: 20.1954\n",
      "Epoch 14/20\n",
      "22687/22687 [==============================] - 23s - loss: 15.3452    \n",
      "Epoch 14/20\n",
      "17385/22687 [=====================>........] - ETA: 5s - loss: 15.5000\n",
      "Epoch 12/20\n",
      "22687/22687 [==============================] - 22s - loss: 15.2702    \n",
      " 3635/22688 [===>..........................] - ETA: 17s - loss: 13.3226Epoch 15/20\n",
      "22687/22687 [==============================] - 22s - loss: 15.2556    \n",
      "  305/22687 [..............................] - ETA: 20s - loss: 13.4600Epoch 15/20\n",
      "22687/22687 [==============================] - 21s - loss: 15.3650    \n",
      " 1785/22687 [=>............................] - ETA: 20s - loss: 15.3069Epoch 15/20\n",
      "22688/22688 [==============================] - 22s - loss: 14.8544    \n",
      "Epoch 13/20\n",
      "21075/22687 [==========================>...] - ETA: 1s - loss: 15.4830\n",
      " 3575/22688 [===>..........................] - ETA: 16s - loss: 14.2769Epoch 16/20\n",
      "22687/22687 [==============================] - 22s - loss: 15.2532    \n",
      "21565/22687 [===========================>..] - ETA: 1s - loss: 15.4291Epoch 16/20\n",
      " 1605/22687 [=>............................] - ETA: 19s - loss: 14.6425\n",
      "Epoch 16/20\n",
      "18790/22687 [=======================>......] - ETA: 4s - loss: 15.3151\n",
      "19215/22687 [========================>.....] - ETA: 3s - loss: 15.1590Epoch 14/20\n",
      "21320/22687 [===========================>..] - ETA: 1s - loss: 15.3979\n",
      "Epoch 17/20\n",
      "22687/22687 [==============================] - 25s - loss: 15.2636    \n",
      "Epoch 17/20\n",
      "22687/22687 [==============================] - 25s - loss: 15.3578    \n",
      " 1330/22687 [>.............................] - ETA: 22s - loss: 15.1500Epoch 17/20\n",
      "22688/22688 [==============================] - 26s - loss: 14.8138    \n",
      "18540/22687 [=======================>......] - ETA: 4s - loss: 15.2802Epoch 15/20\n",
      " 4250/22688 [====>.........................] - ETA: 22s - loss: 14.3381\n",
      "21740/22687 [===========================>..] - ETA: 1s - loss: 15.3379Epoch 18/20\n",
      "22687/22687 [==============================] - 28s - loss: 15.2653    \n",
      "Epoch 18/20\n",
      " 5325/22688 [======>.......................] - ETA: 20s - loss: 14.2238\n",
      "  750/22687 [..............................] - ETA: 30s - loss: 16.6093Epoch 18/20\n",
      "22688/22688 [==============================] - 27s - loss: 14.8213    \n",
      "Epoch 16/20\n",
      "21900/22687 [===========================>..] - ETA: 0s - loss: 15.2155\n",
      " 4240/22688 [====>.........................] - ETA: 20s - loss: 14.5640Epoch 19/20\n",
      " 4765/22688 [=====>........................] - ETA: 19s - loss: 14.4542\n",
      "Epoch 19/20\n",
      "22687/22687 [==============================] - 26s - loss: 15.3441    \n",
      " 5050/22688 [=====>........................] - ETA: 19s - loss: 14.4912Epoch 19/20\n",
      "22688/22688 [==============================] - 22s - loss: 14.8128    \n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22120/22687 [============================>.] - ETA: 0s - loss: 15.3351\n",
      " 4520/22688 [====>.........................] - ETA: 17s - loss: 15.4099Epoch 20/20\n",
      "22687/22687 [==============================] - 22s - loss: 15.2539    \n",
      "Epoch 20/20\n",
      "22687/22687 [==============================] - 22s - loss: 15.3452    \n",
      "Epoch 20/20\n",
      "17175/22687 [=====================>........] - ETA: 5s - loss: 15.4071\n",
      "17880/22687 [======================>.......] - ETA: 4s - loss: 15.2606Epoch 18/20\n",
      "22475/22687 [============================>.] - ETA: 0s - loss: 15.3033\n",
      " 5005/22688 [=====>........................] - ETA: 21s - loss: 14.3410\n",
      "22687/22687 [==============================] - 24s - loss: 15.2649    \n",
      "22688/22688 [==============================] - 20s - loss: 14.8248    \n",
      "Epoch 19/20\n",
      "22688/22688 [==============================] - 14s - loss: 14.8118    \n",
      "Epoch 20/20\n",
      "22688/22688 [==============================] - 11s - loss: 14.8051    \n",
      "5660/5671 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "reg = KerasRegressor(build_fn=mlp_model, \n",
    "                     epochs=20, batch_size=5, verbose=1)\n",
    "imp = Imputer(strategy='mean')\n",
    "scl = StandardScaler()\n",
    "pipeline = Pipeline([('imp', imp), ('scl', scl), ('reg', reg)])\n",
    "\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "y_pred = cross_val_predict(pipeline, X, y,\n",
    "                           cv=cv, groups=grouping,\n",
    "                           verbose=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_pred=y_pred, y_true=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7331466205322847"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_pred=y_pred, y_true=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modified_bland_altman_plot(y_pred, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "residual_plot(y_pred, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "---\n",
    "\n",
    "Our features are only the first ten temperatures of the cycle and the participant's last cycle length and follicular phase length. With it, we achieve a MSE of about 12, which beats the Bortot paper's 15. In terms of use case, this is about equal to the Bortot result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.L_PERIOD.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the median period length is 5, which means that we are really using measurements of BBT during the period to determine the day of ovulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this model has only slight personalization, it's exciting to see how well a personalized model will do."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
